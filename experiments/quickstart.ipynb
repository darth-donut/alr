{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Quick-start\n",
    "\n",
    "This document helps you get up-and-running with `alr` immediately.\n",
    "It should give you a general idea of how to get started with\n",
    "this package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as torchdata\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from alr import MCDropout\n",
    "from alr.acquisition import RandomAcquisition\n",
    "from alr.utils import stratified_partition\n",
    "from alr.data import DataManager, UnlabelledDataset\n",
    "from alr.data.datasets import Dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "data_loader_params = dict(pin_memory=True, num_workers=2, batch_size=32)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we load and prepare our data.\n",
    "Note that we partitioned the training set into labelled and unlabelled sets\n",
    "using `stratified partition` which balances the number of classes in the training pool:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 10000, 59980)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data\n",
    "train, test = Dataset.MNIST.get()\n",
    "pool, train = stratified_partition(train, Dataset.MNIST.about.n_class, 20)\n",
    "pool = UnlabelledDataset(pool)\n",
    "len(train), len(test), len(pool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`MCDropout` lets us define a Bayesian NN. It provides an implementation\n",
    "for `stochastic_forward` which we will use in the next section for the\n",
    "acquisition function.\n",
    "\n",
    "> Notice the dropout layers have been changed to their `Persistent` versions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "MCDropout(\n  (base_model): Net(\n    (fc1): Linear(in_features=784, out_features=1024, bias=True)\n    (drop1): PersistentDropout(p=0.5, inplace=False)\n    (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n    (drop2): PersistentDropout(p=0.5, inplace=False)\n    (fc3): Linear(in_features=2048, out_features=10, bias=True)\n  )\n  (_criterion): CrossEntropyLoss()\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a regular model and an optimiser.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 1024)\n",
    "        self.drop1 = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.drop2 = nn.Dropout()\n",
    "        self.fc3 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.drop1(self.fc1(x)))\n",
    "        x = F.relu(self.drop2(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = MCDropout(Net(), forward=10).to(device)\n",
    "model.compile(criterion=torch.nn.CrossEntropyLoss(),\n",
    "              optimiser=torch.optim.Adam(model.parameters()))\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can instantiate an acquisition function\n",
    "and an associated `DataManager` instance:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ra = RandomAcquisition()\n",
    "dm = DataManager(train, pool, ra)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the vanilla acquisition loop looks like:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition iteration 1 (20.00%), training size: 20\n",
      "\ttrain_acc = 0.96, train_loss = 1.50, test_acc = 0.56                        \n",
      "Acquisition iteration 2 (40.00%), training size: 30\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                       \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                       \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                       \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                       \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                                   \r\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\u001B[A\n",
      "                                                               \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\u001B[A\n",
      "                                                               \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\u001B[A\n",
      "                                                               \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s]\u001B[A\n",
      "                                                               \u001B[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s]\u001B[A\n",
      "Evaluating model:  46%|████▌     | 143/313 [00:05<00:05, 28.75it/s]"
     ]
    }
   ],
   "source": [
    "ITERS = 5\n",
    "EPOCHS = 5\n",
    "accs = {}\n",
    "\n",
    "# In each iteration, acquire `b` points\n",
    "for i in range(ITERS):\n",
    "    print(f\"Acquisition iteration {i + 1} ({(i + 1) / ITERS:.2%}), \"\n",
    "          f\"training size: {dm.n_labelled}\")\n",
    "    # reset weights to original values when the model was first created\n",
    "    model.reset_weights()\n",
    "    # fit = train\n",
    "    result = model.fit(train_loader=torchdata.DataLoader(dm.labelled, **data_loader_params),\n",
    "                       train_acc=True, epochs=EPOCHS, device=device)\n",
    "    # evaluate the model to obtain its test accuracy\n",
    "    test_acc, _ = model.evaluate(data=torchdata.DataLoader(test, **data_loader_params), device=device)\n",
    "    # display results\n",
    "    result.reduce('mean', inplace=True)\n",
    "    print(f\"\\ttrain_acc = {result.train_acc:.2f}, \"\n",
    "          f\"train_loss = {result.train_loss:.2f}, \"\n",
    "          f\"test_acc = {test_acc:.2f}\")\n",
    "    # acquire `b` points from unlabelled pool\n",
    "    dm.acquire(b=10)\n",
    "accs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}