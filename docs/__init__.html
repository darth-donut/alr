
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>alr &#8212; alr 0.0.0b1 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to alr’s documentation!" href="index.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to alr’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">alr 0.0.0b1 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-alr">
<span id="alr"></span><h1>alr<a class="headerlink" href="#module-alr" title="Permalink to this headline">¶</a></h1>
<p>Main alr module</p>
<div class="section" id="classses">
<h2>Classses<a class="headerlink" href="#classses" title="Permalink to this headline">¶</a></h2>
<div class="section" id="alrdataset">
<h3><span class="hidden-section">ALRDataset</span><a class="headerlink" href="#alrdataset" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.ALRDataset">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">ALRDataset</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">y: Optional[numpy.array] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#alr.ALRDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper class to convert numpy arrays into <cite>torch.utils.data.Dataset</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – input features</p></li>
<li><p><strong>y</strong> – Optional, targets</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="alrmodel">
<h3><span class="hidden-section">ALRModel</span><a class="headerlink" href="#alrmodel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.ALRModel">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">ALRModel</code><a class="headerlink" href="#alr.ALRModel" title="Permalink to this definition">¶</a></dt>
<dd><p>A <a class="reference internal" href="#alr.ALRModel" title="alr.ALRModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALRModel</span></code></a> provides generic methods required for common
operations in active learning experiments.</p>
<dl class="method">
<dt id="alr.ALRModel.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#alr.ALRModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Regular forward pass. Usually reserved for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.ALRModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#alr.ALRModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Override this function if predict has a different behaviour from <a class="reference internal" href="#alr.ALRModel.forward" title="alr.ALRModel.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>.
For example, if <a class="reference internal" href="#alr.ALRModel.forward" title="alr.ALRModel.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> returns logits, this function could augment the
output with softmax. Another example would be if the base model is a <a class="reference internal" href="#alr.MCDropout" title="alr.MCDropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCDropout</span></code></a> model,
in which case, this function should return multiple stochastic forward passes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.ALRModel.reset_weights">
<code class="sig-name descname">reset_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#alr.ALRModel.reset_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the model’s weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="acquisitionfunction">
<h3><span class="hidden-section">AcquisitionFunction</span><a class="headerlink" href="#acquisitionfunction" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.AcquisitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">AcquisitionFunction</code><a class="headerlink" href="#alr.AcquisitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>A base class for all acquisition functions. All subclasses should
override the __call__ method.</p>
</dd></dl>

</div>
<div class="section" id="mcdropout">
<h3><span class="hidden-section">MCDropout</span><a class="headerlink" href="#mcdropout" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.MCDropout">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">MCDropout</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">forward: int = 100</em><span class="sig-paren">)</span><a class="headerlink" href="#alr.MCDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements <a class="reference external" href="https://arxiv.org/abs/1506.02142">Monte Carlo Dropout</a> (MCD). The difference between
<a class="reference internal" href="#alr.MCDropout.forward" title="alr.MCDropout.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> and <a class="reference internal" href="#alr.MCDropout.predict" title="alr.MCDropout.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>
is that the former returns a single forward pass (logits) while the
latter returns the mean of <cite>forward</cite> number of passes (softmax scores).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – base <cite>torch.nn.Module</cite> object</p></li>
<li><p><strong>forward</strong> – number of stochastic forward passes</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="alr.MCDropout.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#alr.MCDropout.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Regular forward pass. Raises exception if <cite>self.training</cite> is <cite>False</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.MCDropout.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#alr.MCDropout.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean softmax score of <a class="reference internal" href="#alr.MCDropout.stochastic_forward" title="alr.MCDropout.stochastic_forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">stochastic_forward()</span></code></a> passes.</p>
<p>Equivalent to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stochastic_forward</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.MCDropout.stochastic_forward">
<code class="sig-name descname">stochastic_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#alr.MCDropout.stochastic_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <span class="math notranslate nohighlight">\(m \times N \times C\)</span> <cite>torch.Tensor</cite> where:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(m\)</span> is equal to <cite>self.n_forward</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> is the batch size, equal to <cite>x.size(0)</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of units in the final layer (e.g. number of classes in a classification model)</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor of shape <span class="math notranslate nohighlight">\(m \times N \times C\)</span></p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is the <em>user’s own responsibility</em> to make sure that the model
is in training mode. For example, unless dropout is hard-coded
to always drop units in the base model, stochastic_forward will
not have any stochasticity!</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="datamanager">
<h3><span class="hidden-section">DataManager</span><a class="headerlink" href="#datamanager" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.DataManager">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">DataManager</code><span class="sig-paren">(</span><em class="sig-param">acquirer: alr.AcquisitionFunction</em>, <em class="sig-param">X_train: torch.Tensor</em>, <em class="sig-param">y_train: torch.Tensor</em>, <em class="sig-param">X_pool: torch.Tensor</em>, <em class="sig-param">y_pool: torch.Tensor</em>, <em class="sig-param">device: Optional[torch.device] = None</em>, <em class="sig-param">**data_loader_params</em><span class="sig-paren">)</span><a class="headerlink" href="#alr.DataManager" title="Permalink to this definition">¶</a></dt>
<dd><p>A stateful data manager class</p>
<p>Training data and labels will be updated according to newly acquired samples
as dictated by the provided <cite>acquirer</cite>.
<a class="reference internal" href="#alr.DataManager.training_data" title="alr.DataManager.training_data"><code class="xref py py-attr docutils literal notranslate"><span class="pre">training_data</span></code></a> returns said data
as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> object with the specified <cite>batch_size</cite> in <cite>data_loader_params</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acquirer</strong> – acquisition object</p></li>
<li><p><strong>X_train</strong> – tensor object</p></li>
<li><p><strong>y_train</strong> – tensor object</p></li>
<li><p><strong>X_pool</strong> – tensor object</p></li>
<li><p><strong>y_pool</strong> – tensor object</p></li>
<li><p><strong>device</strong> – torch.device. This will be passed to the acquisition function</p></li>
<li><p><strong>data_loader_params</strong> – keyword parameters to be passed into <cite>DataLoader</cite> when calling
<a class="reference internal" href="#alr.DataManager.training_data" title="alr.DataManager.training_data"><code class="xref py py-attr docutils literal notranslate"><span class="pre">training_data</span></code></a></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="alr.DataManager.acquire">
<code class="sig-name descname">acquire</code><span class="sig-paren">(</span><em class="sig-param">b: int</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#alr.DataManager.acquire" title="Permalink to this definition">¶</a></dt>
<dd><p>Acquires <cite>b</cite> points from the provided <cite>X_pool</cite> according to <cite>acquirer</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>b</strong> – number of points to acquire</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.DataManager.train_size">
<em class="property">property </em><code class="sig-name descname">train_size</code><a class="headerlink" href="#alr.DataManager.train_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Current number of points in <cite>X_train</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><cite>X_train.size(0)</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="alr.DataManager.training_data">
<em class="property">property </em><code class="sig-name descname">training_data</code><a class="headerlink" href="#alr.DataManager.training_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns current training data after being updated by <a class="reference internal" href="#alr.DataManager.acquire" title="alr.DataManager.acquire"><code class="xref py py-meth docutils literal notranslate"><span class="pre">acquire()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><cite>DataLoader</cite> object</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="randomacquisition">
<h3><span class="hidden-section">RandomAcquisition</span><a class="headerlink" href="#randomacquisition" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.RandomAcquisition">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">RandomAcquisition</code><a class="headerlink" href="#alr.RandomAcquisition" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements random acquisition. Uniformly sample <cite>b</cite> indices.</p>
</dd></dl>

</div>
<div class="section" id="bald">
<h3><span class="hidden-section">BALD</span><a class="headerlink" href="#bald" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.BALD">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">BALD</code><span class="sig-paren">(</span><em class="sig-param">model: alr.MCDropout</em>, <em class="sig-param">subset: Optional[int] = -1</em>, <em class="sig-param">device: Optional[torch.device] = None</em>, <em class="sig-param">**data_loader_params</em><span class="sig-paren">)</span><a class="headerlink" href="#alr.BALD" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements <a class="reference external" href="https://arxiv.org/abs/1112.5745">BALD</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{align}
    -\sum_c\left(\frac{1}{T}\sum_t\hat{p}^t_c \right)
     log \left( \frac{1}{T}\sum_t\hat{p}^t_c \right) +
     \frac{1}{T}\sum_{c,t}\hat{p}^t_c log \hat{p}^t_c
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{p}^t_c\)</span> is the softmax output of class <span class="math notranslate nohighlight">\(c\)</span>
on the <span class="math notranslate nohighlight">\(t^{th}\)</span> stochastic iteration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MCDropout</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">bald</span> <span class="o">=</span> <span class="n">BALD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">subset</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">bald</span><span class="p">(</span><span class="n">X_pool</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A <a class="reference internal" href="#alr.MCDropout" title="alr.MCDropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCDropout</span></code></a> model is required to calculate
the <cite>m</cite> different samples of <span class="math notranslate nohighlight">\(p(y | \omega^{(m)})\)</span>.</p></li>
<li><p><strong>subset</strong> – Size of the subset of <cite>X_pool</cite>. Use -1 to denote the entire pool.</p></li>
<li><p><strong>device</strong> – <cite>torch.device</cite> object.</p></li>
<li><p><strong>data_loader_params</strong> – params to be passed into <cite>DataLoader</cite> when
iterating over <cite>X_pool</cite>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Do not set <cite>shuffle=True</cite> in <cite>data_loader_params</cite>! The indices will be
incorrect if the <cite>DataLoader</cite> object shuffles <cite>X_pool</cite>!</p>
</div>
</dd></dl>

</div>
<div class="section" id="ical">
<h3><span class="hidden-section">ICAL</span><a class="headerlink" href="#ical" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="alr.ICAL">
<em class="property">class </em><code class="sig-prename descclassname">alr.</code><code class="sig-name descname">ICAL</code><span class="sig-paren">(</span><em class="sig-param">model: alr.MCDropout, kernel_fn: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, subset: Optional[int] = 200, greedy_acquire: Optional[int] = 1, device: Optional[torch.device] = None, **data_loader_params</em><span class="sig-paren">)</span><a class="headerlink" href="#alr.ICAL" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements ‘normal’ <a class="reference external" href="https://arxiv.org/abs/2002.07916">ICAL</a>. <span class="math notranslate nohighlight">\(R\)</span> points
are randomly drawn from the pool and the average of the candidate batch’s kernels
is used instead. Thus, the dependency measure reduces to <span class="math notranslate nohighlight">\(d = 2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\frac{1}{|\mathcal{R}|} d\text{HSIC}(\displaystyle\sum_{x'\in\mathcal{R}} k^{x'},
\frac{1}{B} \displaystyle\sum_{i = 1}^{B} k^{x_i})\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MCDropout</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">ical</span> <span class="o">=</span> <span class="n">ICAL</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ical</span><span class="p">(</span><span class="n">X_pool</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A <a class="reference internal" href="#alr.MCDropout" title="alr.MCDropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCDropout</span></code></a> model is required to calculate
the <cite>m</cite> different samples of <span class="math notranslate nohighlight">\(p(y | \omega^{(m)})\)</span>.</p></li>
<li><p><strong>kernel_fn</strong> – Kernel function, see static methods of <a class="reference internal" href="#alr.ICAL" title="alr.ICAL"><code class="xref py py-class docutils literal notranslate"><span class="pre">ICAL</span></code></a></p></li>
<li><p><strong>subset</strong> – Normal ICAL uses a subset of <cite>X_pool</cite>. <cite>subset</cite> specifies the
size of this subset (<span class="math notranslate nohighlight">\(|\mathcal{R}|\)</span> in the paper).
Use -1 to denote the entire pool.</p></li>
<li><p><strong>greedy_acquire</strong> – how many points to acquire at once in each acquisition step.</p></li>
<li><p><strong>device</strong> – <cite>torch.device</cite> object.</p></li>
<li><p><strong>data_loader_params</strong> – params to be passed into <cite>DataLoader</cite> when
iterating over <cite>X_pool</cite>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Do not set <cite>shuffle=True</cite> in <cite>data_loader_params</cite>! The indices will be
incorrect if the <cite>DataLoader</cite> object shuffles <cite>X_pool</cite>!</p>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="stratified-partition">
<h3><span class="hidden-section">stratified_partition</span><a class="headerlink" href="#stratified-partition" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="alr.stratified_partition">
<code class="sig-prename descclassname">alr.</code><code class="sig-name descname">stratified_partition</code><span class="sig-paren">(</span><em class="sig-param">X_train: numpy.array</em>, <em class="sig-param">y_train: numpy.array</em>, <em class="sig-param">train_size: int = 20</em><span class="sig-paren">)</span> &#x2192; Tuple[numpy.array, numpy.array, numpy.array, numpy.array]<a class="headerlink" href="#alr.stratified_partition" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns (<cite>X_train</cite>, <cite>y_train</cite>, <cite>X_pool</cite>, <cite>y_pool</cite>) where <cite>X_train.size(0) == train_size</cite> and
<cite>y_train</cite>’s classes are as balanced as possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> – np.array</p></li>
<li><p><strong>y_train</strong> – np.array</p></li>
<li><p><strong>train_size</strong> – <cite>X_train</cite>’s output size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(<cite>X_train</cite>, <cite>y_train</cite>, <cite>X_pool</cite>, <cite>y_pool</cite>) where
<cite>X_train.size(0) == train_size</cite> and
<cite>y_train</cite>’s classes are as balanced as possible.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="run-experiment">
<h3><span class="hidden-section">run_experiment</span><a class="headerlink" href="#run-experiment" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="alr.run_experiment">
<code class="sig-prename descclassname">alr.</code><code class="sig-name descname">run_experiment</code><span class="sig-paren">(</span><em class="sig-param">model: alr.ALRModel</em>, <em class="sig-param">acquisition_function: alr.AcquisitionFunction</em>, <em class="sig-param">X_train: torch.Tensor</em>, <em class="sig-param">y_train: torch.Tensor</em>, <em class="sig-param">X_pool: torch.Tensor</em>, <em class="sig-param">y_pool: torch.Tensor</em>, <em class="sig-param">val_data_loader: torch.utils.data.dataloader.DataLoader</em>, <em class="sig-param">optimiser: torch.optim.optimizer.Optimizer</em>, <em class="sig-param">b: int = 10</em>, <em class="sig-param">iters: int = 98</em>, <em class="sig-param">init_epochs: int = 75</em>, <em class="sig-param">epochs: int = 50</em>, <em class="sig-param">device: Optional[torch.device] = None</em>, <em class="sig-param">pin_memory: bool = True</em>, <em class="sig-param">num_workers: int = 2</em>, <em class="sig-param">batch_size: int = 32</em><span class="sig-paren">)</span> &#x2192; Dict[int, float]<a class="headerlink" href="#alr.run_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper function useful for running a simple train-evaluate-acquire active learning loop.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load pre-processed data into tensor objects</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X_pool</span><span class="p">,</span> <span class="n">y_pool</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># create test dataset and create DataLoader object</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">ALRDataset</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># instantiate model and optimiser.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MCDropout</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="c1"># optional</span>
<span class="n">model</span><span class="o">.</span><span class="n">reset_weights</span><span class="p">()</span>

<span class="n">afunction</span> <span class="o">=</span> <span class="n">RandomAcquisition</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">afunction</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_pool</span><span class="p">,</span> <span class="n">y_pool</span><span class="p">,</span>
                         <span class="n">test_dataset</span><span class="p">,</span> <span class="n">optimiser</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                         <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – an <a class="reference internal" href="#alr.ALRModel" title="alr.ALRModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALRModel</span></code></a> object</p></li>
<li><p><strong>acquisition_function</strong> – an <a class="reference internal" href="#alr.AcquisitionFunction" title="alr.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a> object</p></li>
<li><p><strong>X_train</strong> – A tensor with shape <span class="math notranslate nohighlight">\(N \times C \times H \times W\)</span></p></li>
<li><p><strong>y_train</strong> – A tensor with shape <span class="math notranslate nohighlight">\(N\)</span></p></li>
<li><p><strong>X_pool</strong> – A tensor with shape <span class="math notranslate nohighlight">\(N' \times C \times H \times W\)</span></p></li>
<li><p><strong>y_pool</strong> – A tensor with shape <span class="math notranslate nohighlight">\(N'\)</span></p></li>
<li><p><strong>val_data_loader</strong> – data loader used to calculate test/validation loss/acc</p></li>
<li><p><strong>optimiser</strong> – PyTorch optimiser object</p></li>
<li><p><strong>b</strong> – number of samples to acquire in each iteration</p></li>
<li><p><strong>iters</strong> – number of iterations to repeat acquisition from X_pool</p></li>
<li><p><strong>init_epochs</strong> – number of initial epochs to train</p></li>
<li><p><strong>epochs</strong> – number of epochs for each subsequent training iterations</p></li>
<li><p><strong>device</strong> – torch.device</p></li>
<li><p><strong>pin_memory</strong> – <cite>pin_memory</cite> argument passed to <cite>DataLoader</cite> object when training model</p></li>
<li><p><strong>num_workers</strong> – <cite>num_workers</cite> argument passed to <cite>DataLoader</cite> object when training model</p></li>
<li><p><strong>batch_size</strong> – <cite>batch_size</cite> argument passed to <cite>DataLoader</cite> object when training model</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary of # training points to accuracy</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">alr</a><ul>
<li><a class="reference internal" href="#classses">Classses</a><ul>
<li><a class="reference internal" href="#alrdataset"><span class="hidden-section">ALRDataset</span></a></li>
<li><a class="reference internal" href="#alrmodel"><span class="hidden-section">ALRModel</span></a></li>
<li><a class="reference internal" href="#acquisitionfunction"><span class="hidden-section">AcquisitionFunction</span></a></li>
<li><a class="reference internal" href="#mcdropout"><span class="hidden-section">MCDropout</span></a></li>
<li><a class="reference internal" href="#datamanager"><span class="hidden-section">DataManager</span></a></li>
<li><a class="reference internal" href="#randomacquisition"><span class="hidden-section">RandomAcquisition</span></a></li>
<li><a class="reference internal" href="#bald"><span class="hidden-section">BALD</span></a></li>
<li><a class="reference internal" href="#ical"><span class="hidden-section">ICAL</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#functions">Functions</a><ul>
<li><a class="reference internal" href="#stratified-partition"><span class="hidden-section">stratified_partition</span></a></li>
<li><a class="reference internal" href="#run-experiment"><span class="hidden-section">run_experiment</span></a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Welcome to alr’s documentation!</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/__init__.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to alr’s documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">alr 0.0.0b1 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Jia Hong Fong.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.
    </div>
  </body>
</html>